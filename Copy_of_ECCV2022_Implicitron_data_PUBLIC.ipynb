{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VigneshBaskar/forfun/blob/master/Copy_of_ECCV2022_Implicitron_data_PUBLIC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kllNhJExFhts"
      },
      "outputs": [],
      "source": [
        "# Copyright (c) Meta Platforms, Inc. and affiliates. All rights reserved."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo data\n",
        "In this demo, we show how to access CO3D (v2) dataset using the provided data loaders. We also visualise the images, COLMAP-reconstructed point clouds, and cameras."
      ],
      "metadata": {
        "id": "aA1R0FQHFqSk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Install and import modules\n",
        "\n",
        "Ensure `torch` and `torchvision` are installed. If `pytorch3d` is not installed, install it using the following cell:\n"
      ],
      "metadata": {
        "id": "gzRHN2drFrPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if torch.__version__.startswith(\"1.12.\") and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        !pip install fvcore iopath omegaconf\n",
        "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
        "        !tar xzf 1.10.0.tar.gz\n",
        "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
        "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"
      ],
      "metadata": {
        "id": "rvgq7hweFmEN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d435971c-0cbe-4acb-d38f-979a88007b04"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20220512.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting iopath\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.1 MB/s \n",
            "\u001b[?25hCollecting omegaconf\n",
            "  Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore) (1.21.6)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore) (4.64.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore) (2.0.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore) (0.8.10)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from iopath) (4.1.1)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 49.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: fvcore, iopath, antlr4-python3-runtime\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20220512-py3-none-any.whl size=61288 sha256=e6af43c2e812cc22bf16901f66689b70cf3167ad532aad14fe20aa3846017fb3\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/20/f9/a11a0dd63f4c13678b2a5ec488e48078756505c7777b75b29e\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31549 sha256=1fdb14905cc63c32992b9b6d444c75eeba24abe0d7a06260b1ba12417366a99e\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/cc/ed/ca4e88beef656b01c84b9185196513ef2faf74a5a379b043a7\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=263f163dc6c3d94863aa8cc02f4e13bf3b5445cb52894b07be6e690ef43b6052\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n",
            "Successfully built fvcore iopath antlr4-python3-runtime\n",
            "Installing collected packages: portalocker, yacs, iopath, antlr4-python3-runtime, omegaconf, fvcore\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 fvcore-0.1.5.post20220512 iopath-0.1.10 omegaconf-2.2.3 portalocker-2.6.0 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py37_cu113_pyt1121/download.html\n",
            "Collecting pytorch3d\n",
            "  Downloading https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py37_cu113_pyt1121/pytorch3d-0.7.1-cp37-cp37m-linux_x86_64.whl (47.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.2 MB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: fvcore in /usr/local/lib/python3.7/dist-packages (from pytorch3d) (0.1.5.post20220512)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.7/dist-packages (from pytorch3d) (0.1.10)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d) (2.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d) (1.21.6)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d) (0.1.8)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d) (0.8.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore->pytorch3d) (4.64.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath->pytorch3d) (2.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from iopath->pytorch3d) (4.1.1)\n",
            "Installing collected packages: pytorch3d\n",
            "Successfully installed pytorch3d-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import IPython\n",
        "import imageio\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from pytorch3d.implicitron.dataset.json_index_dataset_map_provider_v2 import JsonIndexDatasetMapProviderV2\n",
        "from pytorch3d.implicitron.tools.config import expand_args_fields\n",
        "from pytorch3d.renderer import join_cameras_as_batch\n",
        "from pytorch3d.vis.plotly_vis import plot_batch_individually, plot_scene"
      ],
      "metadata": {
        "id": "Fgh4DJ0oFvj7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is a subset of CO3D: one apple sequence. We provide it separately to save time and space."
      ],
      "metadata": {
        "id": "rQmwOoFOK8q9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the data\n",
        "!wget https://dl.fbaipublicfiles.com/pytorch3d/data/implicitron_tutorial/co3d_apple_1_sequence.tar.gz\n",
        "!tar -xzf co3d_apple_1_sequence.tar.gz"
      ],
      "metadata": {
        "id": "jrTKP6imFyFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Calling data loaders"
      ],
      "metadata": {
        "id": "EjK5rwSKLQxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_resolution = 80\n",
        "torch.set_printoptions(sci_mode=False)"
      ],
      "metadata": {
        "id": "6NCQoKPCGarn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CO3D_ROOT = \".\"\n",
        "\n",
        "dataset_provider = JsonIndexDatasetMapProviderV2(\n",
        "    category=\"apple\",\n",
        "    subset_name=\"manyview_dev_0\",\n",
        "    dataset_root=CO3D_ROOT,\n",
        "    dataset_JsonIndexDataset_args={\n",
        "        \"load_depths\": False,\n",
        "        \"load_point_clouds\": True,\n",
        "    },\n",
        ")\n",
        "# this is a lightweight provider that loads only metadata but not bolbs like images\n",
        "# e.g. at test time, images can be hidden or unknown.\n",
        "dataset_provider_cameras_only = JsonIndexDatasetMapProviderV2(\n",
        "    category=\"apple\",\n",
        "    subset_name=\"manyview_dev_0\",\n",
        "    dataset_root=CO3D_ROOT,\n",
        "    dataset_JsonIndexDataset_args={\n",
        "        \"box_crop\": False,\n",
        "        \"load_images\": False,\n",
        "        \"load_depths\": False,\n",
        "        \"load_depth_masks\": False,\n",
        "        \"load_masks\": False,\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "l6fsCmhhGqp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_map = dataset_provider.get_dataset_map()"
      ],
      "metadata": {
        "id": "bZSwvUYfGzSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_list  = list(dataset_map.train)"
      ],
      "metadata": {
        "id": "2xuHUW34HSgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is FrameData?\n",
        "\n",
        "The elements of `train_list` are `FrameData` dataclass objects that\n",
        "contain all data fields relevant to the current image / viewpoint.\n",
        "\n",
        "```python\n",
        "@dataclass\n",
        "class FrameData(Mapping[str, Any]):\n",
        "    image_path: Union[str, List[str], None] = None\n",
        "    image_rgb: Optional[torch.Tensor] = None\n",
        "    depth_map: Optional[torch.Tensor] = None\n",
        "    bbox_xywh: Optional[torch.Tensor] = None\n",
        "    camera: Optional[PerspectiveCameras] = None\n",
        "    # many more fields\n",
        "    ...\n",
        "```\n",
        "\n",
        "They can be collated with `FrameData.collate` and unpacked with `**`.\n",
        "Below, we will be using `image_rgb` and `camera` fields."
      ],
      "metadata": {
        "id": "jHAH0aDDJemy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Visualisation"
      ],
      "metadata": {
        "id": "fSKkjqhLLU0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_numpy_image(image):\n",
        "    # Takes an image of shape (C, H, W) in [0,1], where C=3 or 1\n",
        "    # to a numpy uint image of shape (H, W, 3)\n",
        "    return (image * 255).to(torch.uint8).permute(1, 2, 0).detach().cpu().expand(-1, -1, 3).numpy()\n",
        "def resize_image(image):\n",
        "    # Takes images of shape (B, C, H, W) to (B, C, output_resolution, output_resolution)\n",
        "    return torch.nn.functional.interpolate(image, size=(output_resolution, output_resolution))\n",
        "\n",
        "def show_gif(fname):\n",
        "    \"\"\"Show a gif in a bento notebook\"\"\"\n",
        "    with open(fname, \"rb\") as fd:\n",
        "        b64 = base64.b64encode(fd.read()).decode(\"ascii\")\n",
        "    return IPython.display.HTML(f'<img src=\"data:image/gif;base64,{b64}\" />')\n",
        "    \n",
        "images_to_display = [[to_numpy_image(resize_image(a.image_rgb[None])[0])] for a in train_list]\n",
        "n_rows = 7\n",
        "n_images = len(images_to_display)\n",
        "blank_image = images_to_display[0][0] * 0\n",
        "n_per_row = 1+(n_images-1)//n_rows\n",
        "for _ in range(n_per_row*n_rows - n_images):\n",
        "    images_to_display.append([blank_image])\n",
        "\n",
        "split = []\n",
        "for row in range(n_rows):\n",
        "    split.append(images_to_display[row*n_per_row:(row+1)*n_per_row])  \n"
      ],
      "metadata": {
        "id": "4SCL-gMRHT78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_batch_individually(dataset_map.train[0].sequence_point_cloud)"
      ],
      "metadata": {
        "id": "M1XAd5rvHeql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s now show *training* images."
      ],
      "metadata": {
        "id": "91Mg5o8gMoyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image.fromarray(np.block(split))"
      ],
      "metadata": {
        "id": "wiOyxy-MHhWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imageio.mimsave('renders.gif', [im[0] for im in images_to_display])\n",
        "show_gif('renders.gif')"
      ],
      "metadata": {
        "id": "oTDVcPYSL9Ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_cameras = [training_frame.camera for training_frame in dataset_map.train]\n",
        "plot = plot_scene({\"k\": {i: camera for i, camera in enumerate(tr_cameras)}}, camera_scale=0.25)\n",
        "plot.layout.scene.aspectmode = \"data\"\n",
        "plot"
      ],
      "metadata": {
        "id": "l4DbcpISHjOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "union = {i: camera for i, camera in enumerate(tr_cameras)}\n",
        "union[\"cloud\"] = dataset_map.train[0].sequence_point_cloud\n",
        "plot_scene({\"k\": union})"
      ],
      "metadata": {
        "id": "cqSJ418hHk77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_map_cameras = dataset_provider_cameras_only.get_dataset_map()\n",
        "train_cameras = join_cameras_as_batch([frame.camera for frame in dataset_map_cameras.train])\n",
        "#train_cameras=train_cameras[[0,1]]\n",
        "val_cameras = join_cameras_as_batch([frame.camera for frame in dataset_map_cameras.val])\n",
        "test_cameras = join_cameras_as_batch([frame.camera for frame in dataset_map_cameras.test])\n",
        "#test_cameras = test_cameras[[10,11]]"
      ],
      "metadata": {
        "id": "fJLfyVxxH7IL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_scene({name:{\"name\":cameras} for name, cameras in [(\"train\", train_cameras),(\"test\",test_cameras)]}, ncols=2)"
      ],
      "metadata": {
        "id": "YUa41zX8H9BA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Go6eZViRICas"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}