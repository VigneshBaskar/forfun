{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VigneshBaskar/forfun/blob/master/Copy_of_ECCV2022_Implicitron_config_PUBLIC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bb1gjJw3B2cb"
      },
      "outputs": [],
      "source": [
        "# Copyright (c) Meta Platforms, Inc. and affiliates. All rights reserved."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implicitron Config system\n",
        "\n",
        "Goals of the config system:\n",
        "1. Config schema and defaults are defined in the code of the classes; the overridden keys and types of the values are validated before running the code.\n",
        "2. It should be easy to override a parameter deep into the class hierarchy, no need to propagate it through the layers.\n",
        "3. The config system is not intrusive: the classes can be used to instantiate objects in a normal way (with some exceptions).\n",
        "\n"
      ],
      "metadata": {
        "id": "BCU7rJRCCA3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Install and import modules\n",
        "\n",
        "Ensure `torch` and `torchvision` are installed. If `pytorch3d` is not installed, install it using the following cell:\n"
      ],
      "metadata": {
        "id": "wtVZ3G6ackb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if torch.__version__.startswith(\"1.12.\") and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        !pip install fvcore iopath visdom==0.1.8.9 omegaconf\n",
        "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
        "        !tar xzf 1.10.0.tar.gz\n",
        "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
        "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"
      ],
      "metadata": {
        "id": "dZkCBwGLcmZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the data\n",
        "!wget https://dl.fbaipublicfiles.com/pytorch3d/data/implicitron_tutorial/nerf-synthetic-chair.tar.gz\n",
        "!tar -xzf nerf-synthetic-chair.tar.gz"
      ],
      "metadata": {
        "id": "Is46s-M_ZX7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Optional, Tuple\n",
        "import numpy as np\n",
        "import matplotlib.cm\n",
        "import imageio\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import IPython\n",
        "from omegaconf import OmegaConf\n",
        "from PIL import Image\n",
        "from pytorch3d.implicitron.tools.config import Configurable, expand_args_fields, get_default_args, registry, run_auto_creation\n",
        "from pytorch3d.implicitron.dataset.data_source import (\n",
        "    DataSourceBase,\n",
        "    ImplicitronDataSource,\n",
        ")\n",
        "from pytorch3d.implicitron.models.generic_model import ImplicitronModelBase, GenericModel\n",
        "from pytorch3d.implicitron.models.implicit_function.base import ImplicitFunctionBase\n",
        "from pytorch3d.implicitron.models.renderer.base import ImplicitronRayBundle\n",
        "from pytorch3d.renderer import CamerasBase"
      ],
      "metadata": {
        "id": "6eOOS9XZcspO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ToyExperiment(Configurable):\n",
        "  height: int = 5\n",
        "  width: int = 7\n",
        "\n",
        "  def run(self):\n",
        "    print(self.height * self.width)"
      ],
      "metadata": {
        "id": "lr0tHxVAc5j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "defaults = get_default_args(ToyExperiment)\n",
        "print(type(defaults), defaults)"
      ],
      "metadata": {
        "id": "8ESSf4CPdQWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you can instantiate the object from a dict config where data types and keys have been verified to match `ToyExperiment`."
      ],
      "metadata": {
        "id": "Nk18Ik15pejP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ToyExperiment(**defaults).run()"
      ],
      "metadata": {
        "id": "XJoDn-9qdXc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We often override parameters from CLI or a yaml file after parsing them with `OmegaConf.from_dotlist` or `OmegaConf.create`, respectively. The former can be done e.g. like:\n",
        "\n",
        "```\n",
        "python experiment.py height=3 \n",
        "```\n",
        "\n",
        "If you use Hydra, it will do that for you."
      ],
      "metadata": {
        "id": "z6hy87kVfWdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "override = OmegaConf.from_dotlist([\"height=3\"])\n",
        "updated = OmegaConf.merge(defaults, override)\n",
        "print(updated)\n",
        "ToyExperiment(**updated).run()"
      ],
      "metadata": {
        "id": "sLMC3s7ods1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# type checking; EITHER LINE IS SUPPOSED TO RAISE AN ERROR\n",
        "\n",
        "OmegaConf.merge(defaults, OmegaConf.from_dotlist([\"not_a_param=5\"]))\n",
        "OmegaConf.merge(defaults, OmegaConf.from_dotlist([\"height=NotInteger\"]))"
      ],
      "metadata": {
        "id": "xx41Wf0HfIiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Default Implicitron Experiment config\n",
        "\n",
        "In pracrice, the object structure (and thus configs) form a hierarchy. Let’s see how it is used in Implicitron. The top-level config may be defined like this:\n"
      ],
      "metadata": {
        "id": "6F1i4pl9g-Bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Experiment(Configurable):\n",
        "    data_source: DataSourceBase\n",
        "    data_source_class_type: str = \"ImplicitronDataSource\"\n",
        "    model_factory: ImplicitronModelBase\n",
        "    model_factory_class_type: str = \"GenericModel\"\n",
        "\n",
        "    def __post_init__(self):\n",
        "        run_auto_creation(self)\n",
        "\n",
        "    def run(self):\n",
        "        # your training loop caling `model.forward()`\n",
        "        pass"
      ],
      "metadata": {
        "id": "YOsSOWPNeXg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s check what those classes are:\n",
        "\n",
        "```python\n",
        "class DataSourceBase(ReplaceableBase):\n",
        "  ...\n",
        "\n",
        "@registry.register\n",
        "class ImplicitronDataSource(DataSourceBase):\n",
        "    dataset_map_provider: DatasetMapProviderBase\n",
        "    dataset_map_provider_class_type: str = \"\"\n",
        "    data_loader_map_provider: DataLoaderMapProviderBase\n",
        "    data_loader_map_provider_class_type: str = \"SequenceDataLoaderMapProvider\"\n",
        "  ...\n",
        "```"
      ],
      "metadata": {
        "id": "D88CEkWDi4Kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "defaults = get_default_args(Experiment)"
      ],
      "metadata": {
        "id": "b0VPdZgejBnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(OmegaConf.to_yaml(defaults)[:600] + \"\\n...\")"
      ],
      "metadata": {
        "id": "_hCirUu0k3so"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some things to note here:\n",
        "\n",
        "1. The default config picked up all available implementations of ReplaceableBase classes, e.g. for `dataset_map_provider`, it found in the registry `BlenderDatasetMapProvider` and `JsonIndexDatasetMapProvider`.\n",
        "2. There are the fields with `???` that have to be overriden (e.g. from CLI or yaml file) before instantiating. Let’s do that:"
      ],
      "metadata": {
        "id": "xPzuDdqflkGO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Overridding defaults and instantiating the hierarchy"
      ],
      "metadata": {
        "id": "3ndUo_sWqsMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "override_dotlist = OmegaConf.from_dotlist([\n",
        "    \"data_source_ImplicitronDataSource_args.dataset_map_provider_class_type=BlenderDatasetMapProvider\",\n",
        "])\n",
        "\n",
        "# we can also override them in yaml, which looks more concise\n",
        "override_yaml = OmegaConf.create(\"\"\"\n",
        "data_source_ImplicitronDataSource_args:\n",
        "    dataset_map_provider_BlenderDatasetMapProvider_args:\n",
        "        base_dir: ./chair\n",
        "        object_name: chair\n",
        "\"\"\")\n",
        "updated = OmegaConf.merge(defaults, override_yaml, override_dotlist)"
      ],
      "metadata": {
        "id": "nJJQqD7gk6_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(OmegaConf.to_yaml(updated)[:500] + \"\\n...\")"
      ],
      "metadata": {
        "id": "c3fJRwJSnhPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this creates the objects all the way down!\n",
        "instance = Experiment(**updated)"
      ],
      "metadata": {
        "id": "LyVxakkqnuX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets, dataloaders = instance.data_source.get_datasets_and_dataloaders()\n"
      ],
      "metadata": {
        "id": "HuN0w-xpoEaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(datasets[\"train\"][32].camera.R)"
      ],
      "metadata": {
        "id": "BQgF5P5_ei50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image.fromarray((datasets[\"train\"][32].image_rgb.permute(1, 2, 0).data * 255.).byte().cpu().numpy())"
      ],
      "metadata": {
        "id": "jw2dj4qtdySx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. `implicitron_trainer` project\n",
        "\n",
        "We provide a template Experiment definition and the set of configs to run the common methods (NeRF, IDR, SRN, etc.) in `pytorch3d/projects/implicitron_trainer/experiment.py`. You can reuse it or take as a starting point. For example, to train a NeRF on a CO3D scene, you can run\n",
        "\n",
        "```sh\n",
        "dataset_args=data_source_ImplicitronDataSource_args.dataset_map_provider_JsonIndexDatasetMapProvider_args\n",
        "pytorch3d_implicitron_runner --config-path ./configs/ --config-name repro_singleseq_nerf \\\n",
        "    $dataset_args.dataset_root=<DATASET_ROOT> $dataset_args.category='skateboard' \\\n",
        "    $dataset_args.test_restrict_sequence_id=0 test_when_finished=True exp_dir=<CHECKPOINT_DIR>\n",
        "```\n",
        "\n",
        "NOTE: this section is NOT self-contained and is not wupposed to be executed."
      ],
      "metadata": {
        "id": "Foo2CuckF4kn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use case: implement a new implicit function."
      ],
      "metadata": {
        "id": "9P0IVy-iIPLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@registry.register\n",
        "class MyImplicitFunction(ImplicitFunctionBase, torch.nn.Module):\n",
        "    # parameters...\n",
        "\n",
        "    def __post_init__(self) -> None:\n",
        "        super().__init__()  # this is necessary if we derive from nn.Module\n",
        "        run_auto_creation(self)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        ray_bundle: ImplicitronRayBundle,\n",
        "        fun_viewpool=None,\n",
        "        camera: Optional[CamerasBase] = None,\n",
        "        global_code=None,\n",
        "        **kwargs,\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor, Dict]:\n",
        "        # evaluate opacity and colour in the points defined by ray_bundle\n",
        "        opacity = torch.empty()\n",
        "        color = torch.empty()\n",
        "        return opacity, color, {}"
      ],
      "metadata": {
        "id": "0-KSwGTfIOGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import this code from `experiment.py`. You can now enable this implicit function by setting the key\n",
        "`model_factory_ImplicitronModelFactory_args.model_GenericModel_args.implicit_function_class_type=MyImplicitFunction`"
      ],
      "metadata": {
        "id": "FVVvvACmLQU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use case: define a new dataset.\n",
        "\n",
        "Imageine you have made a several photos and estimated cameras with COLMAP.\n",
        "They are stored in files `image_000.jpg`, `image_001.jpg`, ..., and the corresponding estimated viewpoints are stored in the COLMAP-produced binary file in OpenCV format."
      ],
      "metadata": {
        "id": "AFdkCumoLA89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from pytorch3d.utils import cameras_from_opencv_projection\n",
        "from pytorch3d.implicitron.dataset.dataset_map_provider import DatasetMap, DatasetMapProviderBase, SingleSceneDataset, DATASET_TYPE_KNOWN\n",
        "from .colmap_scripts import read_write_model"
      ],
      "metadata": {
        "id": "tBp3YGffQhnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_cameras(colmap_scene_dir):\n",
        "    # read_model is provided by COLMAP:\n",
        "    # https://github.com/colmap/colmap/blob/dev/scripts/python/read_write_model.py\n",
        "    calibs, images, points3D = read_write_model.read_model(colmap_scene_dir, \".bin\")\n",
        "    cameras = {}\n",
        "    for image_meta in images.values():\n",
        "        intrinsic = calibs[image_meta.camera_id]\n",
        "        assert intrinsic.model == \"OPENCV\"\n",
        "        # qvec2rotmat is another function from read_write_model.py\n",
        "        R = read_write_model.qvec2rotmat(image_meta.qvec)[:3, :3]\n",
        "        t = np.array(image_meta.tvec)\n",
        "\n",
        "        fx, fy, p0x, p0y = intrinsic.params[:4]\n",
        "        distortion_coeffs_np = intrinsic.params[4:]\n",
        "        imsize = np.array([intrinsic.height, intrinsic.width])\n",
        "        K = np.eye(3).astype(np.float32)\n",
        "        K[0, 0] = fx\n",
        "        K[1, 1] = fy\n",
        "        K[0, 2] = p0x\n",
        "        K[1, 2] = p0y\n",
        "\n",
        "        camera_pt3d = cameras_from_opencv_projection(\n",
        "            torch.from_numpy(R)[None].float(),\n",
        "            torch.from_numpy(t)[None].float(),\n",
        "            torch.from_numpy(K)[None].float(),\n",
        "            torch.from_numpy(imsize)[None].long(),\n",
        "        )\n",
        "        cameras[image_meta.name] = camera_pt3d\n",
        "    \n",
        "    return cameras"
      ],
      "metadata": {
        "id": "9SgYaMSFPUEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@registry.register\n",
        "class MyDataset(DatasetMapProviderBase):\n",
        "    base_dir: str\n",
        "    colmap_scene_dir: str\n",
        "\n",
        "    # load data here\n",
        "    def __post_init__(self) -> None:\n",
        "        run_auto_creation(self)\n",
        "\n",
        "        image_files = sorted(fname for fname in os.listdir(self.base_dir) if fname.startswith(\"image\"))\n",
        "        self.images = [torchvision.io.read_image(fname) for fname in image_files]\n",
        "        cameras_dict = read_cameras(self.colmap_scene_dir)\n",
        "        self.cameras = [cameras_dict[image] for image in image_files]\n",
        "        \n",
        "\n",
        "    def get_dataset_map(self) -> DatasetMap:\n",
        "        return DatasetMap(\n",
        "            train=self._get_dataset(),  # for simplicity, we do not define splits\n",
        "            val=self._get_dataset(),\n",
        "            test=self._get_dataset(),\n",
        "        )\n",
        "\n",
        "    def _get_dataset(self):\n",
        "        return SingleSceneDataset(\n",
        "            object_name=\"my_object\",\n",
        "            images=self.images,\n",
        "            poses=self.cameras,\n",
        "            frame_types=[DATASET_TYPE_KNOWN] * len(self.images),\n",
        "        )"
      ],
      "metadata": {
        "id": "aXzCK7SZo65z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import this code from `experiment.py`. You can now enable this implicit function by setting the key\n",
        "\n",
        "`data_source_ImplicitronDataSource_args.dataset_map_provider_class_type=MyDataset`\n",
        "\n"
      ],
      "metadata": {
        "id": "6SKytfmmUtz3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NaaQq3rtUtNn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}