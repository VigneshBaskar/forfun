{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VigneshBaskar/forfun/blob/master/Copy_of_ECCV_voxel_grid_training_with_implicitron_PUBLIC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "947ee02f-bbfe-494b-8fd3-fddf4e6c8b8e",
        "showInput": true,
        "customInput": null,
        "requestMsgId": "947ee02f-bbfe-494b-8fd3-fddf4e6c8b8e",
        "customOutput": null,
        "executionStartTime": 1665701655990,
        "executionStopTime": 1665701656002,
        "id": "cBTA3NAzcJDj"
      },
      "source": [
        "# Copyright (c) Meta Platforms, Inc. and affiliates. All rights reserved."
      ],
      "execution_count": null,
      "outputs": [],
      "id": "cBTA3NAzcJDj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "a48a9dcf-e80f-474b-a0c4-2c9a765b15c5",
        "showInput": false,
        "customInput": null,
        "id": "S30lAfAZcJDp"
      },
      "source": [
        "# Demo of Voxel grid training\n",
        "In this demo, we show some training with an implicitron model on a blender synthetic scene"
      ],
      "id": "S30lAfAZcJDp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "51337c0e-ad27-4b75-ad6a-737dca5d7b95",
        "showInput": false,
        "customInput": null,
        "id": "zrcK7hGgcJDs"
      },
      "source": [
        "## 0. Install and import modules\n",
        "\n",
        "Ensure `torch` and `torchvision` are installed. (On Colab, they are already present). If `pytorch3d` is not installed, install it using the following cell:\n"
      ],
      "id": "zrcK7hGgcJDs"
    },
    {
      "cell_type": "code",
      "metadata": {
        "originalKey": "e9203adc-b5aa-4e1f-a401-afee8a42d19a",
        "showInput": true,
        "customInput": null,
        "requestMsgId": "5d9e6290-f730-49fd-a556-ebfe7a8fe701",
        "customOutput": null,
        "executionStartTime": 1666532495801,
        "executionStopTime": 1666532502675,
        "id": "ZipZXE10cJDu"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "need_pytorch3d=False\n",
        "try:\n",
        "    import pytorch3d\n",
        "except ModuleNotFoundError:\n",
        "    need_pytorch3d=True\n",
        "if need_pytorch3d:\n",
        "    if torch.__version__.startswith(\"1.12.\") and sys.platform.startswith(\"linux\"):\n",
        "        # We try to install PyTorch3D via a released wheel.\n",
        "        pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "        version_str=\"\".join([\n",
        "            f\"py3{sys.version_info.minor}_cu\",\n",
        "            torch.version.cuda.replace(\".\",\"\"),\n",
        "            f\"_pyt{pyt_version_str}\"\n",
        "        ])\n",
        "        !pip install fvcore iopath\n",
        "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
        "    else:\n",
        "        # We try to install PyTorch3D from source.\n",
        "        !curl -LO https://github.com/NVIDIA/cub/archive/1.10.0.tar.gz\n",
        "        !tar xzf 1.10.0.tar.gz\n",
        "        os.environ[\"CUB_HOME\"] = os.getcwd() + \"/cub-1.10.0\"\n",
        "        !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "ZipZXE10cJDu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "originalKey": "2c1020e6-eb4a-4644-9719-9147500d8e4f",
        "showInput": false,
        "customInput": null,
        "id": "oiaRNgSEcJDw"
      },
      "source": [
        "Ensure omegaconf is installed. If not, run this cell. (On colab, this is needed, but despite the warning it is not necessary to restart the runtime.)"
      ],
      "id": "oiaRNgSEcJDw"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install omegaconf"
      ],
      "metadata": {
        "id": "pUEaJH4gcfJW"
      },
      "execution_count": null,
      "outputs": [],
      "id": "pUEaJH4gcfJW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download one scene from the Blender synthetic dataset."
      ],
      "metadata": {
        "id": "SU8pnlStccM7"
      },
      "id": "SU8pnlStccM7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83bf02e1",
      "metadata": {
        "id": "83bf02e1"
      },
      "outputs": [],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/pytorch3d/data/implicitron_tutorial/nerf-synthetic-chair.tar.gz\n",
        "!tar -xzf nerf-synthetic-chair.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d102823d",
      "metadata": {
        "id": "d102823d"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import logging\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from pathlib import Path\n",
        "from typing import Iterator, Tuple\n",
        "\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import tqdm\n",
        "from IPython.display import HTML\n",
        "from omegaconf import OmegaConf\n",
        "from PIL import Image\n",
        "from pytorch3d.implicitron.dataset.dataset_base import FrameData\n",
        "from pytorch3d.implicitron.dataset.data_loader_map_provider import SequenceDataLoaderMapProvider\n",
        "from pytorch3d.implicitron.dataset.blender_dataset_map_provider import BlenderDatasetMapProvider\n",
        "from pytorch3d.implicitron.models.generic_model import GenericModel\n",
        "from pytorch3d.implicitron.models.implicit_function.base import ImplicitFunctionBase\n",
        "from pytorch3d.implicitron.models.renderer.base import EvaluationMode\n",
        "from pytorch3d.implicitron.tools.config import expand_args_fields, get_default_args, registry, remove_unused_components\n",
        "from pytorch3d.implicitron.tools.stats import Stats\n",
        "from pytorch3d.renderer import RayBundle\n",
        "from pytorch3d.renderer.implicit.renderer import VolumeSampler\n",
        "from pytorch3d.structures import Volumes\n",
        "from pytorch3d.vis.plotly_vis import plot_batch_individually, plot_scene"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f9be6fa",
      "metadata": {
        "id": "9f9be6fa"
      },
      "outputs": [],
      "source": [
        "torch.set_printoptions(sci_mode=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`BlenderDatasetMapProvider` in implicitron reads data formatted on disk like the blender dataset"
      ],
      "metadata": {
        "id": "zmvGKojACe7p"
      },
      "id": "zmvGKojACe7p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4509b2d8",
      "metadata": {
        "id": "4509b2d8"
      },
      "outputs": [],
      "source": [
        "provider = BlenderDatasetMapProvider(\n",
        "    base_dir=\"./chair\",\n",
        "    object_name=\"chair\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a8aab37",
      "metadata": {
        "id": "8a8aab37"
      },
      "outputs": [],
      "source": [
        "dataset_map = provider.get_dataset_map()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define the configuration for the model in yaml. This includes choosing the components we wish to use (e.g. implicit function, raysampler) as well as parameters of the many components."
      ],
      "metadata": {
        "id": "lBLUuyFsBc7v"
      },
      "id": "lBLUuyFsBc7v"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ba1f0bf",
      "metadata": {
        "id": "0ba1f0bf"
      },
      "outputs": [],
      "source": [
        "model_yaml = \"\"\"\\\n",
        "model_factory_ImplicitronModelFactory_args:\n",
        "  model_GenericModel_args:\n",
        "    render_image_width: 800\n",
        "    render_image_height: 800\n",
        "    mask_images: False\n",
        "    mask_threshold: 0\n",
        "    n_train_target_views: -1\n",
        "    num_passes: 1\n",
        "    chunk_size_grid: 16000\n",
        "    implicit_function_class_type: VoxelGridImplicitFunction\n",
        "    implicit_function_VoxelGridImplicitFunction_args:\n",
        "      scaffold_calculating_epochs:\n",
        "        - 1\n",
        "        - 2\n",
        "        - 3\n",
        "        - 4\n",
        "        - 5      \n",
        "      #scaffold_resolution: Tuple[int, int, int] = (128, 128, 128)\n",
        "      scaffold_empty_space_threshold: 0.01\n",
        "      scaffold_filter_points: false\n",
        "      volume_cropping_epochs:\n",
        "        - 1\n",
        "        - 2\n",
        "        - 3\n",
        "        - 4\n",
        "        - 5\n",
        "\n",
        "      voxel_grid_density_args:\n",
        "        param_groups:\n",
        "          self: \"grids\"\n",
        "        voxel_grid_class_type: VMFactorizedVoxelGrid\n",
        "        voxel_grid_VMFactorizedVoxelGrid_args:\n",
        "          n_features: 1\n",
        "          n_components: 48\n",
        "          basis_matrix: False\n",
        "          resolution_changes:\n",
        "            0:\n",
        "              - 128\n",
        "              - 128\n",
        "              - 128\n",
        "            3:\n",
        "              - 256\n",
        "              - 256\n",
        "              - 256\n",
        "            6:\n",
        "              - 500\n",
        "              - 500\n",
        "              - 500\n",
        "        extents:\n",
        "          - 6.5\n",
        "          - 6.5\n",
        "          - 6.5\n",
        "      voxel_grid_color_args:\n",
        "        param_groups:\n",
        "          self: \"grids\"\n",
        "        voxel_grid_class_type: VMFactorizedVoxelGrid\n",
        "        voxel_grid_VMFactorizedVoxelGrid_args:\n",
        "          n_features: 27\n",
        "          n_components: 144\n",
        "          resolution_changes:\n",
        "            0:\n",
        "              - 128\n",
        "              - 128\n",
        "              - 128\n",
        "            3:\n",
        "              - 256\n",
        "              - 256\n",
        "              - 256\n",
        "            6:\n",
        "              - 500\n",
        "              - 500\n",
        "              - 500\n",
        "        extents:\n",
        "          - 6.5\n",
        "          - 6.5\n",
        "          - 6.5\n",
        "      harmonic_embedder_xyz_density_args:\n",
        "        n_harmonic_functions: 0\n",
        "      harmonic_embedder_xyz_color_args:\n",
        "        n_harmonic_functions: 2\n",
        "      harmonic_embedder_dir_color_args:\n",
        "        n_harmonic_functions: 2\n",
        "      decoder_density_class_type: ElementwiseDecoder\n",
        "      decoder_density_ElementwiseDecoder_args:\n",
        "        operation: SOFTPLUS\n",
        "        scale: 1\n",
        "        shift: -5 # -10 ?\n",
        "      decoder_color_class_type: MLPDecoder\n",
        "      decoder_color_MLPDecoder_args:\n",
        "        network_args:\n",
        "          n_layers: 2\n",
        "          output_dim: 3\n",
        "          hidden_dim: 128\n",
        "          last_activation: SIGMOID\n",
        "          last_layer_bias_init: 0.0\n",
        "          use_xavier_init: false\n",
        "\n",
        "    raysampler_class_type: NearFarRaySampler\n",
        "    raysampler_NearFarRaySampler_args:\n",
        "      n_rays_total_training: 1024\n",
        "      n_rays_per_image_sampled_from_mask: null\n",
        "      n_pts_per_ray_training: 512 #64 norm(resolution)/0.5\n",
        "      min_depth: 2.0\n",
        "      max_depth: 6.0\n",
        "    renderer_MultiPassEmissionAbsorptionRenderer_args:\n",
        "      density_noise_std_train: 0.0\n",
        "      n_pts_per_ray_fine_training: 128\n",
        "      n_pts_per_ray_fine_evaluation: 128\n",
        "      raymarcher_EmissionAbsorptionRaymarcher_args:\n",
        "        blend_output: false\n",
        "        background_opacity: 0.0\n",
        "        replicate_last_interval: true\n",
        "        bg_color:\n",
        "        - 0.0\n",
        "    loss_weights:\n",
        "      loss_rgb_mse: 1.0\n",
        "      loss_prev_stage_rgb_mse: 0.0\n",
        "      loss_mask_bce: 0.0\n",
        "      loss_prev_stage_mask_bce: 0.0\n",
        "      loss_autodecoder_norm: 0.00\n",
        "\n",
        "    # suppress progress bars\n",
        "    tqdm_trigger_threshold: 19000 \n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa763519",
      "metadata": {
        "id": "fa763519"
      },
      "outputs": [],
      "source": [
        "model_cfg = OmegaConf.create(model_yaml)\n",
        "model_cfg_full = OmegaConf.merge(get_default_args(GenericModel), model_cfg.model_factory_ImplicitronModelFactory_args.model_GenericModel_args)\n",
        "gm = GenericModel(**model_cfg_full)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "995fee66",
      "metadata": {
        "id": "995fee66"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    gm.to(device)\n",
        "    assert next(gm.parameters()).is_cuda\n",
        "else:\n",
        "    print(\"CPU ONLY\")\n",
        "    device = torch.device(\"cpu\") ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ab54794",
      "metadata": {
        "id": "3ab54794"
      },
      "outputs": [],
      "source": [
        "gm.train();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea26349",
      "metadata": {
        "id": "5ea26349"
      },
      "outputs": [],
      "source": [
        "for name, param in gm.named_parameters():\n",
        "    print(f\"{name.ljust(75)} {tuple(param.shape)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bde81a1f",
      "metadata": {
        "id": "bde81a1f"
      },
      "outputs": [],
      "source": [
        "def make_optimizer():\n",
        "    decoder_params = [j for i,j in gm.named_parameters() if \"voxel_grid\" not in i if j.requires_grad]\n",
        "    grid_params = [j for i,j in gm.named_parameters() if \"voxel_grid\" in i if j.requires_grad]\n",
        "    p_groups = [\n",
        "        {\"params\": decoder_params, \"lr\": 0.001},\n",
        "        {\"params\": grid_params, \"lr\": 0.02},\n",
        "    ]\n",
        "    lr = 0.001\n",
        "    \n",
        "    optimizer = torch.optim.Adam(p_groups, foreach=True, lr=lr, weight_decay=0.0, betas=[0.9, 0.999])\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
        "        optimizer,\n",
        "        lambda epoch: 0.1 ** (epoch / 3001),\n",
        "        verbose=False,\n",
        "    )\n",
        "    return optimizer, scheduler\n",
        "\n",
        "\n",
        "optimizer, scheduler = make_optimizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a dataloader which will provide all the training data (as a FrameData) in every iteration, \n",
        "with 1000 iterations as an \"epoch\"."
      ],
      "metadata": {
        "id": "HiOiqwrXAmN3"
      },
      "id": "HiOiqwrXAmN3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e70ee24",
      "metadata": {
        "id": "8e70ee24"
      },
      "outputs": [],
      "source": [
        "class WholeDatasetLoader:\n",
        "    \"\"\"\n",
        "    Loades the whole dataset on device and provides and iterator over it.\n",
        "    Returns `n_batches_in_epoch` batches, where one batch is the whole\n",
        "    dataset.\n",
        "\n",
        "    Members:\n",
        "        train_dataset: dataset to load\n",
        "        n_batches_in_epoch: how many batches to have in an epoch.\n",
        "        device: torch.device on which to load the dataset,\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, train_dataset, n_batches_in_epoch: int, device: torch.device\n",
        "    ) -> None:\n",
        "        self.n_batches_in_epoch = n_batches_in_epoch\n",
        "        # pyre-ignore[6]\n",
        "        train_data = [train_dataset[i] for i in range(len(train_dataset))]\n",
        "        self.train_dataset_batch = train_data[0].collate(train_data).to(device)\n",
        "\n",
        "    def __iter__(self) -> Iterator[FrameData]:\n",
        "        return itertools.repeat(self.train_dataset_batch, self.n_batches_in_epoch)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.n_batches_in_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc1d356d",
      "metadata": {
        "id": "cc1d356d"
      },
      "outputs": [],
      "source": [
        "loader = WholeDatasetLoader(dataset_map.train, 1000, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "List of events which happen at each epoch"
      ],
      "metadata": {
        "id": "vZ1qL6O9AL04"
      },
      "id": "vZ1qL6O9AL04"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49dabe17",
      "metadata": {
        "id": "49dabe17"
      },
      "outputs": [],
      "source": [
        "subscribers = defaultdict(list)\n",
        "def _collect_epoch_subscribers(module: torch.nn.Module) -> None:\n",
        "    subscribe_to_epochs = getattr(module, \"subscribe_to_epochs\", None)\n",
        "    if callable(subscribe_to_epochs):\n",
        "        wanted_epochs, apply_func = subscribe_to_epochs()\n",
        "        for epoch in wanted_epochs:\n",
        "            # pyre-ignore[16]\n",
        "            subscribers[epoch].append(apply_func)\n",
        "gm.apply(_collect_epoch_subscribers);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stats object keeps running average losses for us"
      ],
      "metadata": {
        "id": "Ys1FD9B_AE6i"
      },
      "id": "Ys1FD9B_AE6i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddd5a5fc",
      "metadata": {
        "id": "ddd5a5fc"
      },
      "outputs": [],
      "source": [
        "stats = Stats(gm.log_vars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fa00b97",
      "metadata": {
        "scrolled": false,
        "id": "0fa00b97"
      },
      "outputs": [],
      "source": [
        "def train_epoch(epoch):\n",
        "    global optimizer, preds, scheduler\n",
        "    print(f\"doing epoch {epoch}\")\n",
        "    our_subscribers = subscribers[epoch]\n",
        "    change = len(our_subscribers) > 0\n",
        "    for subscriber in our_subscribers:\n",
        "        subscriber(epoch)\n",
        "    if change:\n",
        "        optimizer, scheduler = make_optimizer()\n",
        "        for _ in range(epoch):\n",
        "            scheduler.step()\n",
        "    stats.new_epoch()\n",
        "    t_start = time.time()\n",
        "    for it, net_input in enumerate(loader):  # enumerate(tqdm.tqdm(loader)):\n",
        "        net_input = net_input.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        preds = gm(**{**net_input, \"evaluation_mode\": EvaluationMode.TRAINING})\n",
        "        preds[\"objective\"].backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        stats.update(preds, time_start=t_start)\n",
        "        if it % 100 == 0:\n",
        "            # print(f\"objective: {float(preds['objective']):.5f}, rgb_psnr: {float(preds['loss_rgb_psnr']):.5f}\")\n",
        "            stats.print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "031524b5",
      "metadata": {
        "id": "031524b5"
      },
      "source": [
        "### Do a little bit of training and visualise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c3468be",
      "metadata": {
        "id": "1c3468be"
      },
      "outputs": [],
      "source": [
        "train_epoch(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed82d44d",
      "metadata": {
        "id": "ed82d44d"
      },
      "outputs": [],
      "source": [
        "train_data_collated = [FrameData.collate([frame.to(device)]) for frame in dataset_map.train]\n",
        "test_data_collated = [FrameData.collate([frame.to(device)]) for frame in dataset_map.test]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcf63c95",
      "metadata": {
        "id": "fcf63c95"
      },
      "outputs": [],
      "source": [
        "def to_numpy_image(image):\n",
        "    # Takes an image of shape (C, H, W) in [0,1], where C=3 or 1\n",
        "    # to a numpy uint image of shape (H, W, 3)\n",
        "    return (image * 255).to(torch.uint8).permute(1, 2, 0).detach().cpu().expand(-1, -1, 3).numpy()\n",
        "def resize_image(image, output_resolution):\n",
        "    if output_resolution is None:\n",
        "        return image\n",
        "    # Takes images of shape (B, C, H, W) to (B, C, output_resolution, output_resolution)\n",
        "    return torch.nn.functional.interpolate(image, size=(output_resolution, output_resolution))\n",
        "\n",
        "def image_data(collated_frames, output_resolution=100):\n",
        "    gm.eval()\n",
        "    images = []\n",
        "    expected = []\n",
        "    masks = []\n",
        "    masks_expected = []\n",
        "    psnrs = []\n",
        "    for frame in tqdm.tqdm(collated_frames):\n",
        "        with torch.inference_mode():\n",
        "            out = gm(**frame, evaluation_mode=EvaluationMode.EVALUATION)\n",
        "            rendered_image = torch.clamp(out[\"images_render\"],0,1)\n",
        "            \n",
        "        image_rgb = to_numpy_image(resize_image(rendered_image, output_resolution)[0])\n",
        "        mask = to_numpy_image(resize_image(out[\"masks_render\"], output_resolution)[0])\n",
        "        expd = to_numpy_image(resize_image(frame.image_rgb, output_resolution)[0])\n",
        "        mask_expected = to_numpy_image(resize_image(frame.fg_probability, output_resolution)[0])\n",
        "\n",
        "        images.append(image_rgb)\n",
        "        expected.append(expd)\n",
        "        masks.append(mask)\n",
        "        masks_expected.append(mask_expected)\n",
        "        psnrs.append(float(out[\"loss_rgb_psnr\"]))\n",
        "    return [images, expected, masks, masks_expected, psnrs]\n",
        "\n",
        "def make_mosaic(images, expected, masks, masks_expected, n_rows=1):\n",
        "    images_to_display = [images.copy(), expected.copy(), masks.copy(), masks_expected.copy()]\n",
        "    n_images = len(images)\n",
        "    blank_image = images[0] * 0\n",
        "    n_per_row = 1+(n_images-1)//n_rows\n",
        "    for _ in range(n_per_row*n_rows - n_images):\n",
        "        for group in images_to_display:\n",
        "            group.append(blank_image)\n",
        "\n",
        "    images_to_display_listed = [[[i] for i in j] for j in images_to_display]\n",
        "    split = []\n",
        "    for row in range(n_rows):\n",
        "        for group in images_to_display_listed:\n",
        "            split.append(group[row*n_per_row:(row+1)*n_per_row])  \n",
        "\n",
        "    return Image.fromarray(np.block(split))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "511028c6",
      "metadata": {
        "id": "511028c6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfd824fb",
      "metadata": {
        "id": "dfd824fb"
      },
      "outputs": [],
      "source": [
        "train_image_data = image_data(train_data_collated[::20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa2adcfe",
      "metadata": {
        "id": "aa2adcfe"
      },
      "outputs": [],
      "source": [
        "#TRAIN\n",
        "print(\"train psnrs\", train_image_data[4])\n",
        "make_mosaic(*train_image_data[:4])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_data = image_data(test_data_collated[::40])"
      ],
      "metadata": {
        "id": "3ZVszPqoDH2S"
      },
      "id": "3ZVszPqoDH2S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "336753f3",
      "metadata": {
        "id": "336753f3"
      },
      "outputs": [],
      "source": [
        "#TEST\n",
        "print(\"test psnrs\", test_image_data[4])\n",
        "make_mosaic(*test_image_data[:4], n_rows=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3952a6e2",
      "metadata": {
        "id": "3952a6e2"
      },
      "source": [
        "### Do more training and visualise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b72156fe",
      "metadata": {
        "id": "b72156fe"
      },
      "outputs": [],
      "source": [
        "gm.train()\n",
        "for epoch in range(1, 6):\n",
        "    train_epoch(epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eaaa0c8",
      "metadata": {
        "id": "8eaaa0c8"
      },
      "outputs": [],
      "source": [
        "train_image_data = image_data(train_data_collated[::20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d466f7e",
      "metadata": {
        "id": "3d466f7e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8ecd9cc",
      "metadata": {
        "id": "f8ecd9cc"
      },
      "outputs": [],
      "source": [
        "#TRAIN\n",
        "print(\"train psnrs\", train_image_data[4])\n",
        "make_mosaic(*train_image_data[:4])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4cc60e5",
      "metadata": {
        "id": "c4cc60e5"
      },
      "outputs": [],
      "source": [
        "test_image_data = image_data(test_data_collated[::40])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ba39eef",
      "metadata": {
        "id": "9ba39eef"
      },
      "outputs": [],
      "source": [
        "#TEST\n",
        "print(\"test psnrs\", test_image_data[4])\n",
        "make_mosaic(*test_image_data[:4], n_rows=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9be54346",
      "metadata": {
        "id": "9be54346"
      },
      "outputs": [],
      "source": [
        "one_full_train_image = image_data(train_data_collated[:1], output_resolution=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c387f22",
      "metadata": {
        "id": "2c387f22"
      },
      "outputs": [],
      "source": [
        "make_mosaic(*one_full_train_image[:4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2def163d",
      "metadata": {
        "id": "2def163d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15f3989d",
      "metadata": {
        "id": "15f3989d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}